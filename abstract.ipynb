{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Kesamaan Abstrak Artikel Jurnal\n",
    "\n",
    "## Deskripsi Proyek\n",
    "Program ini dirancang untuk menganalisis kesamaan abstrak dari beberapa artikel jurnal menggunakan teknik *Text Mining*. Proses ini mencakup pengambilan abstrak dari halaman web, penerjemahan teks ke bahasa Inggris, pembersihan data, hingga perhitungan kesamaan antar teks menggunakan *TF-IDF* dan *Cosine Similarity*.\n",
    "\n",
    "## Tujuan\n",
    "- Mengambil abstrak artikel jurnal secara otomatis dari tautan yang disediakan.\n",
    "- Menerjemahkan abstrak ke bahasa Inggris agar seragam.\n",
    "- Membersihkan teks dengan menghilangkan elemen-elemen yang tidak relevan, seperti tanda baca dan kata-kata umum (*stopwords*).\n",
    "- Mengukur tingkat kemiripan antar artikel berdasarkan teks abstrak mereka.\n",
    "- Menyimpan hasil analisis kesamaan dalam format tabel untuk evaluasi lebih lanjut.\n",
    "\n",
    "## Alur Proses\n",
    "1. **Pengambilan Data**:\n",
    "   - Program mengakses halaman jurnal untuk mengambil abstrak menggunakan pustaka `requests` dan `BeautifulSoup`.\n",
    "2. **Penerjemahan**:\n",
    "   - Abstrak diterjemahkan ke bahasa Inggris menggunakan pustaka `translate`.\n",
    "3. **Pembersihan Teks**:\n",
    "   - Teks abstrak dibersihkan dari tanda baca, huruf kapital, dan kata-kata tidak penting menggunakan `nltk`.\n",
    "4. **Penghitungan Kesamaan**:\n",
    "   - Abstrak dibandingkan menggunakan metode *TF-IDF Vectorization* dan *Cosine Similarity* dari pustaka `scikit-learn`.\n",
    "5. **Hasil Akhir**:\n",
    "   - Tingkat kesamaan antar abstrak ditampilkan dalam bentuk tabel matriks dan disimpan sebagai file CSV untuk analisis lebih lanjut.\n",
    "\n",
    "## Kegunaan\n",
    "Kode ini bermanfaat untuk peneliti, akademisi, atau pengelola jurnal yang ingin memahami hubungan atau kemiripan antara artikel yang diterbitkan, sehingga dapat membantu dalam analisis bibliometrik atau rekomendasi artikel serupa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instal Dependencies\n",
    "%pip install requests beautifulsoup4 translate nltk scikit-learn pandas tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library yang Dibutuhkan\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Download stopwords NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_links = [\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/91857\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/82107\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/85834\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/87393\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/88081\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/90030\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/90062\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/90165\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/90437\",\n",
    "    \"https://jurnal.ugm.ac.id/ijccs/article/view/92636\",\n",
    "]\n",
    "\n",
    "def translate_text(text, target_lang='en', max_retries=3):\n",
    "    \"\"\"\n",
    "    Menerjemahkan teks dengan penanganan kesalahan\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Membuat penerjemah untuk bahasa Inggris\n",
    "            translator = Translator(to_lang=target_lang)\n",
    "            \n",
    "            # Menerjemahkan teks\n",
    "            translated_text = translator.translate(text)\n",
    "            \n",
    "            # Memeriksa apakah terjemahan bermakna\n",
    "            if translated_text and translated_text.strip():\n",
    "                return translated_text\n",
    "            \n",
    "            # Jika terjemahan kosong, tunggu dan coba lagi\n",
    "            time.sleep(1 * (attempt + 1))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Percobaan penerjemahan {attempt + 1} gagal: {e}\")\n",
    "            time.sleep(1)\n",
    "    \n",
    "    # Kembali ke teks asli jika semua percobaan gagal\n",
    "    print(\"Penerjemahan gagal\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_titles_and_abstracts(links):\n",
    "    titles_abstracts = {}\n",
    "    for link in links:\n",
    "        try:\n",
    "            # Add delay to avoid overwhelming the server\n",
    "            time.sleep(random.uniform(0.5, 2))\n",
    "\n",
    "            # Send request with user-agent\n",
    "            response = requests.get(link, headers={\n",
    "                'User-Agent': 'Mozilla/5.0 ...'\n",
    "            })\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Extract the title\n",
    "            title_tag = soup.find('meta', attrs={'name': 'DC.Title'})\n",
    "            title = title_tag['content'] if title_tag else \"Title not found\"\n",
    "\n",
    "            # Extract the abstract\n",
    "            abstract_div = soup.find('div', id='articleAbstract')\n",
    "            abstract = abstract_div.get_text(strip=True) if abstract_div else \"Abstract not found\"\n",
    "\n",
    "            titles_abstracts[link] = {\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract\n",
    "            }\n",
    "        except Exception as e:\n",
    "            titles_abstracts[link] = {\n",
    "                \"title\": f\"Error fetching title: {e}\",\n",
    "                \"abstract\": f\"Error fetching abstract: {e}\"\n",
    "            }\n",
    "    return titles_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Ubah ke huruf kecil\n",
    "    text = text.lower()\n",
    "    # Hapus tanda baca\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    # Hapus stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_abstracts(titles_abstracts):\n",
    "    # Preprocess the abstracts\n",
    "    processed_abstracts = [preprocess_text(data[\"abstract\"]) for data in titles_abstracts.values()]\n",
    "\n",
    "    # Vectorize the abstracts using TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed_abstracts)\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Create a DataFrame to store the similarity results\n",
    "    similarity_df = pd.DataFrame(np.round(cosine_sim_matrix, 4), \n",
    "        index=[f\"Article {i+1}\" for i in range(len(titles_abstracts))], \n",
    "        columns=[f\"Article {i+1}\" for i in range(len(titles_abstracts))])\n",
    "    \n",
    "    return similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Titles:\n",
      "Article 1: Anomaly Detection of Hospital Claim Using Support Vector Regression\n",
      "Article 2: The Adoption of Blockchain Technology the Business Using Structural Equation Modelling\n",
      "Article 3: Ensemble Method for Anomaly Detection On the Internet of Things\n",
      "Article 4: Webcam-Based Bus Passenger Detection System Using Single Shot Detector Method\n",
      "Article 5: Rule-Based Natural Language Processing in Volcanic Ash Data Searching System\n",
      "Article 6: Modeling OTP Delivery Notification Status through a Causality Bayesian Network\n",
      "Article 7: Maintaining Query Performance through  Table Rebuilding & Archiving\n",
      "Article 8: Multivariat Predict Sales Data Using the Recurrent Neural Network (RNN) Method\n",
      "Article 9: Effect of Hyperparameter Tuning Using Random Search on Tree-Based Classification Algorithm for Software Defect Prediction\n",
      "Article 10: DEVELOPMENTS AND TRENDS IN CYBERSECURITY AGAINST HUMAN FACTORS AND TIME PRESSURE USING BIBLIOMETRIC ANALYSIS\n",
      "\n",
      "Similarity Table:\n",
      "╒════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═════════════╤═════════════╤══════════════╕\n",
      "│            │   Article 1 │   Article 2 │   Article 3 │   Article 4 │   Article 5 │   Article 6 │   Article 7 │   Article 8 │   Article 9 │   Article 10 │\n",
      "╞════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪══════════════╡\n",
      "│ Article 1  │      1      │      0.0227 │      0.0667 │      0.0439 │      0.0342 │      0.0082 │      0.0061 │      0.0032 │      0.0228 │       0      │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 2  │      0.0227 │      1      │      0.081  │      0.0214 │      0.077  │      0.0393 │      0.0158 │      0.0795 │      0.0457 │       0.0042 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 3  │      0.0667 │      0.081  │      1      │      0.0414 │      0.0876 │      0.0501 │      0.0305 │      0.1154 │      0.0191 │       0.0192 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 4  │      0.0439 │      0.0214 │      0.0414 │      1      │      0.0452 │      0.0313 │      0.0198 │      0.0534 │      0.0187 │       0.0021 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 5  │      0.0342 │      0.077  │      0.0876 │      0.0452 │      1      │      0.0153 │      0.0147 │      0.0594 │      0.0429 │       0.0051 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 6  │      0.0082 │      0.0393 │      0.0501 │      0.0313 │      0.0153 │      1      │      0.0275 │      0.0484 │      0.0116 │       0.0013 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 7  │      0.0061 │      0.0158 │      0.0305 │      0.0198 │      0.0147 │      0.0275 │      1      │      0.0172 │      0.0071 │       0.0225 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 8  │      0.0032 │      0.0795 │      0.1154 │      0.0534 │      0.0594 │      0.0484 │      0.0172 │      1      │      0.0212 │       0.005  │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 9  │      0.0228 │      0.0457 │      0.0191 │      0.0187 │      0.0429 │      0.0116 │      0.0071 │      0.0212 │      1      │       0.0061 │\n",
      "├────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼─────────────┼──────────────┤\n",
      "│ Article 10 │      0      │      0.0042 │      0.0192 │      0.0021 │      0.0051 │      0.0013 │      0.0225 │      0.005  │      0.0061 │       1      │\n",
      "╘════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═════════════╧═════════════╧══════════════╛\n",
      "\n",
      "Similarity table saved to abstract_similarity.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Fetch the titles and abstracts\n",
    "        titles_abstracts = fetch_titles_and_abstracts(article_links)\n",
    "\n",
    "        # Compare abstracts and get the similarity table\n",
    "        similarity_table = compare_abstracts(titles_abstracts)\n",
    "\n",
    "        # Print the titles for reference\n",
    "        print(\"Article Titles:\")\n",
    "        for i, (link, data) in enumerate(titles_abstracts.items(), start=1):\n",
    "            print(f\"Article {i}: {data['title']}\")\n",
    "\n",
    "        # Display the similarity table in a nice format\n",
    "        print(\"\\nSimilarity Table:\")\n",
    "        print(tabulate(similarity_table, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "        # Save to CSV (optional)\n",
    "        similarity_table.to_csv('abstract_similarity.csv')\n",
    "        print(\"\\nSimilarity table saved to abstract_similarity.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
